{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from typing import List, Union\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print\n",
    "\n",
    "from brain.sdk import BrainClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_client = BrainClient(\"http://127.0.0.1:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer to the input query\")\n",
    "    reasoning: str = Field(..., description=\"The reasoning behind the answer\")\n",
    "\n",
    "class RuleModification(BaseModel):\n",
    "    rule_number: int = Field(..., description=\"The rule number to modify\")\n",
    "    new_content: str = Field(..., description=\"The new content for the rule\")\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    feedback: str = Field(..., description=\"Feedback on the previous answer\")\n",
    "    keep_rules: List[int] = Field(..., description=\"Rule numbers to keep\")\n",
    "    modify_rules: List[RuleModification] = Field(default_factory=list, description=\"Rules to modify\")\n",
    "    new_rules: List[str] = Field(default_factory=list, description=\"New rules to add\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, content: str, rule_id: int):\n",
    "        self.content = content\n",
    "        self.rule_id = rule_id\n",
    "        self.created_at = datetime.now()\n",
    "        self.last_updated = datetime.now()\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"memory.json\"):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.rules: Dict[int, Rule] = {}\n",
    "        self.next_rule_id = 1\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        data = json.loads(self.file_path.read_text())\n",
    "        self.next_rule_id = data['next_rule_id']\n",
    "        self.rules = {\n",
    "            int(rule_id): Rule(\n",
    "                content=rule['content'],\n",
    "                rule_id=int(rule_id)\n",
    "            )\n",
    "            for rule_id, rule in data['rules'].items()\n",
    "        }\n",
    "\n",
    "    def _save(self):\n",
    "        data = {\n",
    "            'next_rule_id': self.next_rule_id,\n",
    "            'rules': {\n",
    "                str(rule_id): {\n",
    "                    'content': rule.content,\n",
    "                }\n",
    "                for rule_id, rule in self.rules.items()\n",
    "            }\n",
    "        }\n",
    "        self.file_path.write_text(json.dumps(data, indent=2))\n",
    "\n",
    "    def get_rules_context(self) -> str:\n",
    "        # if not self.rules:\n",
    "        #     return \"No existing rules.\"\n",
    "        \n",
    "        return \"Current rules:\\n\" + \"\\n\".join(\n",
    "            f\"{rule.rule_id}. {rule.content}\"\n",
    "            for rule in sorted(self.rules.values(), key=lambda x: x.rule_id)\n",
    "        )\n",
    "\n",
    "    def update_from_feedback(self, feedback: FeedbackResult):\n",
    "        # Convert current rules to set for easier processing\n",
    "        current_rule_ids = set(self.rules.keys())\n",
    "        keep_rules = set(feedback.keep_rules)\n",
    "        \n",
    "        # Remove rules not in keep_rules\n",
    "        rules_to_remove = current_rule_ids - keep_rules\n",
    "        if rules_to_remove:\n",
    "            for rule_id in rules_to_remove:\n",
    "                self.rules.pop(rule_id, None)\n",
    "\n",
    "        # Modify existing rules\n",
    "        if feedback.modify_rules:\n",
    "            for modification in feedback.modify_rules:\n",
    "                if modification.rule_number in self.rules:\n",
    "                    self.rules[modification.rule_number].content = modification.new_content\n",
    "                    self.rules[modification.rule_number].last_updated = datetime.now()\n",
    "\n",
    "        # Add new rules\n",
    "        if feedback.new_rules:\n",
    "            for content in feedback.new_rules:\n",
    "                rule = Rule(content=content, rule_id=self.next_rule_id)\n",
    "                self.rules[self.next_rule_id] = rule\n",
    "                self.next_rule_id += 1\n",
    "\n",
    "        self._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, context: str):\n",
    "    system_prompt = \"\"\"You are an agent designed to provide answers based on learned rules.\n",
    "Apply the rules wisely - not every rule needs to be used for every answer.\n",
    "You are an agent that uses knowledge to generate accurate, generalized answers. \n",
    "Focus on principles and patterns, not specific memorization. Use the context provided to:\n",
    "1. Identify underlying patterns.\n",
    "2. Apply generalized knowledge to new inputs.\n",
    "Reason out the answer based on the rules you have learned.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Query: {input_query}\n",
    "\n",
    "{context}\n",
    "\n",
    "Using these rules as guidelines, provide your answer:\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(main_goal: str, input_query: str, answer: OperationalResult, correct_answer: str, context: str):\n",
    "    system_prompt = f\"\"\"You are a learning feedback agent focused on extracting deep insights aligned with a specific goal.\n",
    "\n",
    "MAIN GOAL: {main_goal}\n",
    "\n",
    "Your purpose is to help the system learn HOW to achieve this goal by:\n",
    "1. Analyzing differences between given answers and correct answers\n",
    "2. Extracting detailed knowledge that helps achieve the main goal\n",
    "3. Creating comprehensive rules that guide future responses\n",
    "4. Building a knowledge base focused on the goal's requirements\n",
    "\n",
    "Core Analysis Principles:\n",
    "- Extract general patterns, not specific solutions\n",
    "- Look for underlying principles that achieve the goal\n",
    "- Focus on knowledge that transfers to new situations\n",
    "- Identify what knowledge would help achieve better answers\n",
    "- Consider what deep understanding is missing\n",
    "- Think about what fundamental concepts would improve performance\n",
    "\n",
    "Rules/Knowledge Requirements:\n",
    "- Must directly relate to achieving the main goal\n",
    "- Should be detailed and comprehensive\n",
    "- Must be generally applicable\n",
    "- Should capture underlying principles\n",
    "- Must focus on transferable knowledge\n",
    "- Should build on existing understanding\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"DEEP LEARNING ANALYSIS:\n",
    "\n",
    "GOAL TO ACHIEVE: {main_goal}\n",
    "\n",
    "Current Learning Instance:\n",
    "Input: {input_query}\n",
    "Current Output: {answer.answer}\n",
    "Current Reasoning: {answer.reasoning}\n",
    "Expected Output: {correct_answer}\n",
    "\n",
    "Existing Knowledge Base:\n",
    "{context}\n",
    "\n",
    "Perform Deep Analysis:\n",
    "1. What fundamental understanding would help achieve the goal here?\n",
    "2. What deeper patterns reveal themselves when comparing outputs?\n",
    "3. What core principles would improve goal achievement?\n",
    "4. What essential knowledge is missing from our current rules?\n",
    "5. What broader understanding would help with similar goals?\n",
    "\n",
    "Provide:\n",
    "1. Rich Analysis: Detailed feedback about what we can learn regarding our goal\n",
    "2. Retained Knowledge: List numbers of rules that contain valid, goal-relevant principles\n",
    "3. Knowledge Updates: List [[rule_number, \"enhanced knowledge or principle\"]]\n",
    "4. New Understanding: Add detailed new rules that capture essential goal-relevant knowledge\n",
    "\n",
    "Focus Areas:\n",
    "- Deep understanding over surface patterns\n",
    "- Core principles over specific solutions\n",
    "- Transferable knowledge over contextual details\n",
    "- Fundamental concepts over specific applications\n",
    "- Goal achievement mechanisms over input-output pairs\n",
    "Your goal is to help the system learn to achieve its main goal by analyzing successes and failures.\n",
    "- Identify positive patterns that led to correct answers.\n",
    "- Identify negative patterns or gaps that caused failures.\n",
    "- Provide insights to refine knowledge for future queries.\n",
    "- Focus on creating rules or principles that generalize well.\n",
    "\n",
    "\n",
    "- If something is working give positive feedback so that the system can learn from it\n",
    "- If something is not working give negative feedback so that the system can learn from it\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(\n",
    "    input_query: str,\n",
    "    correct_answer: Optional[str] = None,\n",
    "    main_goal: str = \"Learn to provide accurate and consistent responses\",\n",
    "    memory: Memory = None,\n",
    "):\n",
    "    if memory is None:\n",
    "        memory = Memory()\n",
    "    context = memory.get_rules_context()\n",
    "    # Get answer using current rules\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query, context=context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Get feedback and evolve rules\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            answer=result,\n",
    "            correct_answer=correct_answer,\n",
    "            context=context,\n",
    "        )\n",
    "        # Update memory based on feedback\n",
    "        memory.update_from_feedback(feedback)\n",
    "\n",
    "        return {\"answer\": result.answer, \"feedback\": feedback}\n",
    "\n",
    "    return {\"answer\": result.answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = \"What is the capital of France?\"\n",
    "# result1 = process_query(\n",
    "#     input_query=query1,\n",
    "#     correct_answer=\"Paris.\",\n",
    "#     main_goal=\"Learn how to format the answer exactly in given style\"\n",
    "# )\n",
    "# print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Answer: ellohay | Correct Answer: Ellohay\n",
      "System Answer: orldway | Correct Answer: Orldway\n",
      "System Answer: ythonpay | Correct Answer: Ythonpay\n",
      "System Answer: odecay | Correct Answer: Odecay\n",
      "System Answer: earnlay | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"query\": \"Transform 'hello'\",\n",
    "        \"correct_answer\": \"Ellohay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'world'\",\n",
    "        \"correct_answer\": \"Orldway\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'python'\",\n",
    "        \"correct_answer\": \"Ythonpay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'code'\",\n",
    "        \"correct_answer\": \"Odecay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'learn'\",\n",
    "        \"correct_answer\": \"Earnlay\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    memory = Memory()  # Reset memory for fresh learning\n",
    "    \n",
    "    for _ in range(1):\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            \n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation pattern that converts the input to output\"\n",
    "            )\n",
    "            \n",
    "            print(f\"System Answer: {result['answer']} | Correct Answer: {example['correct_answer']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn sfn | Correct Answer: ysu\n",
      "System Answer: cre8 life | Correct Answer: osi\n",
      "System Answer: evolve | Correct Answer: enr\n",
      "System Answer: Prac makes perf | Correct Answer: rae\n",
      "System Answer: Power of knowledge | Correct Answer: nso\n",
      "System Answer: AI is the future. | Correct Answer: ishu\n",
      "System Answer: data informs choices | Correct Answer: are\n",
      "System Answer: science is wonderful | Correct Answer: csm\n",
      "System Answer: akl | Correct Answer: lee\n",
      "System Answer: prsvrncpysf | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: ptyh | Correct Answer: ysu\n",
      "System Answer: cde is lf | Correct Answer: osi\n",
      "System Answer: evolve | Correct Answer: enr\n",
      "System Answer: practc mks perfct | Correct Answer: rae\n",
      "System Answer: knwlge pwr | Correct Answer: nso\n",
      "System Answer: AI: Future | Correct Answer: ishu\n",
      "System Answer: data drives decisions | Correct Answer: are\n",
      "System Answer: Sci is awe | Correct Answer: csm\n",
      "System Answer: Learn continually | Correct Answer: lee\n",
      "System Answer: try, succeed | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn fn | Correct Answer: ysu\n",
      "System Answer: cd is lf | Correct Answer: osi\n",
      "System Answer: lrn & grw | Correct Answer: enr\n",
      "System Answer: prctc mks prfct | Correct Answer: rae\n",
      "System Answer: kno j pow | Correct Answer: nso\n",
      "System Answer: A.I. = future | Correct Answer: ishu\n",
      "System Answer: dta drvz dcssns | Correct Answer: are\n",
      "System Answer: scnc mzn | Correct Answer: csm\n",
      "System Answer: lwy klrn | Correct Answer: lee\n",
      "System Answer: prsrvnce pz ff | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn fyn | Correct Answer: ysu\n",
      "System Answer: C0D3 L1F3 | Correct Answer: osi\n",
      "System Answer: evolve | Correct Answer: enr\n",
      "System Answer: Prctcmksprct | Correct Answer: rae\n",
      "System Answer: Kwnoledge iz pwur | Correct Answer: nso\n",
      "System Answer: A.I. is our future | Correct Answer: ishu\n",
      "System Answer: dætə drɪvz dɪ'sɪʒənz | Correct Answer: are\n",
      "System Answer: Science Rocks | Correct Answer: csm\n",
      "System Answer: Lifelong learning | Correct Answer: lee\n",
      "System Answer: Persistence is rewarding. | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn fyn | Correct Answer: ysu\n",
      "System Answer: lifecode | Correct Answer: osi\n",
      "System Answer: lrn & gro | Correct Answer: enr\n",
      "System Answer: prctc mk prfct | Correct Answer: rae\n",
      "System Answer: nlj pwr | Correct Answer: nso\n",
      "System Answer: ay-futur | Correct Answer: ishu\n",
      "System Answer: dta drv dcsn | Correct Answer: are\n",
      "System Answer: scnsmz | Correct Answer: csm\n",
      "System Answer: learn | Correct Answer: lee\n",
      "System Answer: prsvrncpysf | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn is fn | Correct Answer: ysu\n",
      "System Answer: cde lv | Correct Answer: osi\n",
      "System Answer: lrn & grw | Correct Answer: enr\n",
      "System Answer: pract perf | Correct Answer: rae\n",
      "System Answer: Kno pow | Correct Answer: nso\n",
      "System Answer: A.I. is future | Correct Answer: ishu\n",
      "System Answer: dta drv dcn | Correct Answer: are\n",
      "System Answer: sci amaz | Correct Answer: csm\n",
      "System Answer: lways keep lrn | Correct Answer: lee\n",
      "System Answer: prsrvn pz off | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: pythn fn | Correct Answer: ysu\n",
      "System Answer: c d s l f | Correct Answer: osi\n",
      "System Answer: lrn & grw | Correct Answer: enr\n",
      "System Answer: pract. mks perf. | Correct Answer: rae\n",
      "System Answer: knwlg pwr | Correct Answer: nso\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 66\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Answer\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Correct Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtrain_pattern_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[146], line 56\u001b[0m, in \u001b[0;36mtrain_pattern_learner\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on one epoch...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_examples, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# print(f\"Training Example {i}: {example['query']}\")\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorrect_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorrect_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmain_goal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLearn the hidden transformation rule that converts the input to output, and return the correct output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Answer\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Correct Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[143], line 11\u001b[0m, in \u001b[0;36mprocess_query\u001b[0;34m(input_query, correct_answer, main_goal, memory)\u001b[0m\n\u001b[1;32m      9\u001b[0m context \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mget_rules_context()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get answer using current rules\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mbrain_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperational_reasoner_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m correct_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Get feedback and evolve rules\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     feedback \u001b[38;5;241m=\u001b[39m brain_client\u001b[38;5;241m.\u001b[39muse(feedback_reasoner_id)(\n\u001b[1;32m     18\u001b[0m         main_goal\u001b[38;5;241m=\u001b[39mmain_goal,\n\u001b[1;32m     19\u001b[0m         input_query\u001b[38;5;241m=\u001b[39minput_query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m     23\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/notebooks/learner/../../brain/sdk.py:45\u001b[0m, in \u001b[0;36mBrainClient.use.<locals>.wrapper\u001b[0;34m(**inputs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session_id:\n\u001b[1;32m     44\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m session_id\n\u001b[0;32m---> 45\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/execute_reasoner/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     49\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/personal_projects/brain-v1/.conda/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from builtins import print\n",
    "\n",
    "\n",
    "def transform_sentence(sentence,n=2):\n",
    "    n-=1\n",
    "    words = sentence.split()\n",
    "    transformed = ''.join(word[n] for word in words if len(word) >=n)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "# Training and testing data generation\n",
    "sentences = [\n",
    "    \"python is fun\",\n",
    "    \"code is life\",\n",
    "    \"learn and grow\",\n",
    "    \"practice makes perfect\",\n",
    "    \"knowledge is power\",\n",
    "    \"ai is the future\",\n",
    "    \"data drives decisions\",\n",
    "    \"science is amazing\",\n",
    "    \"always keep learning\",\n",
    "    \"perseverance pays off\",\n",
    "    \"learning is ongoing\",\n",
    "    \"practice brings mastery\",\n",
    "    \"knowledge fuels creativity\",\n",
    "    \"transform ideas daily\",\n",
    "    \"explore and create\",\n",
    "    \"analyze your potential\",\n",
    "    \"never stop growing\",\n",
    "    \"think outside boundaries\",\n",
    "    \"focus on improvement\",\n",
    "    \"believe in progress\"\n",
    "]\n",
    "\n",
    "nth_word=2\n",
    "# Generate examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": f\"Transform '{sentence}'\",\n",
    "        \"correct_answer\": transform_sentence(sentence,n=nth_word)\n",
    "    }\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "# Split examples into training and testing (10 each)\n",
    "training_examples = examples[:10]\n",
    "testing_examples = examples[10:]\n",
    "\n",
    "\n",
    "# Modified train_pattern_learner function\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(file_path=\"memory_n2.json\")  # Reset memory for fresh learning\n",
    "    for _ in range(10):\n",
    "        print(\"Training on one epoch...\\n\")\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            # print(f\"Training Example {i}: {example['query']}\")\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation rule that converts the input to output, and return the correct output\",\n",
    "                memory=memory,\n",
    "            )\n",
    "            print(f\"System Answer: {result.get('answer', 'No Answer')} | Correct Answer: {example['correct_answer']}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced multi memory CLU\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Input Query] --> B[Operational Reasoner]\n",
    "    B --> C[Generated Answer]\n",
    "    C --> D[Feedback Reasoner]\n",
    "    E[Correct Answer] --> D\n",
    "    F[Main Goal] --> D\n",
    "    \n",
    "    subgraph Memory System\n",
    "        G[Pattern Memory]\n",
    "        H[Success Memory]\n",
    "        I[Failure Memory]\n",
    "        J[Confidence Tracker]\n",
    "    end\n",
    "    \n",
    "    G --> B\n",
    "    H --> B\n",
    "    I --> B\n",
    "    J --> B\n",
    "    \n",
    "    D --> K[Memory Manager]\n",
    "    K --> G\n",
    "    K --> H\n",
    "    K --> I\n",
    "    K --> J\n",
    "\n",
    "    subgraph Feedback Analysis\n",
    "        L[Pattern Extractor]\n",
    "        M[Success Analyzer]\n",
    "        N[Failure Analyzer]\n",
    "        O[Confidence Updater]\n",
    "    end\n",
    "    \n",
    "    D --> L\n",
    "    D --> M\n",
    "    D --> N\n",
    "    D --> O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class MemoryEntry:\n",
    "    def __init__(self, content: str, knowledge_type: str, entry_id: int):\n",
    "        self.content = content  # Generalized rule/knowledge\n",
    "        self.knowledge_type = knowledge_type  # 'positive', 'negative', 'general'\n",
    "        self.entry_id = entry_id\n",
    "        self.created_at = datetime.now()\n",
    "        self.last_updated = datetime.now()\n",
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"memory.json\"):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.entries: Dict[int, MemoryEntry] = {}\n",
    "        self.next_entry_id = 1\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            # Initialize with default values if the file does not exist\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            data = json.loads(self.file_path.read_text())\n",
    "            self.next_entry_id = data.get('next_entry_id', 1)  # Default to 1 if key is missing\n",
    "            self.entries = {\n",
    "                int(entry_id): MemoryEntry(\n",
    "                    content=entry['content'],\n",
    "                    knowledge_type=entry['knowledge_type'],\n",
    "                    entry_id=int(entry_id)\n",
    "                )\n",
    "                for entry_id, entry in data.get('entries', {}).items()  # Default to empty if 'entries' is missing\n",
    "            }\n",
    "        except (json.JSONDecodeError, KeyError):\n",
    "            # If the file is corrupted or has unexpected structure, reinitialize\n",
    "            self.next_entry_id = 1\n",
    "            self.entries = {}\n",
    "            self._save()\n",
    "\n",
    "\n",
    "    def _save(self):\n",
    "        data = {\n",
    "            'next_entry_id': self.next_entry_id,\n",
    "            'entries': {\n",
    "                str(entry_id): {\n",
    "                    'content': entry.content,\n",
    "                    'knowledge_type': entry.knowledge_type\n",
    "                }\n",
    "                for entry_id, entry in self.entries.items()\n",
    "            }\n",
    "        }\n",
    "        self.file_path.write_text(json.dumps(data, indent=2))\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        positive_knowledge = [\n",
    "            f\"{entry.entry_id}. {entry.content}\"\n",
    "            for entry in sorted(self.entries.values(), key=lambda x: x.entry_id)\n",
    "            if entry.knowledge_type == \"positive\"\n",
    "        ]\n",
    "\n",
    "        general_knowledge = [\n",
    "            f\"{entry.entry_id}. {entry.content}\"\n",
    "            for entry in sorted(self.entries.values(), key=lambda x: x.entry_id)\n",
    "            if entry.knowledge_type == \"general\"\n",
    "        ]\n",
    "\n",
    "        negative_knowledge = [\n",
    "            f\"{entry.entry_id}. {entry.content}\"\n",
    "            for entry in sorted(self.entries.values(), key=lambda x: x.entry_id)\n",
    "            if entry.knowledge_type == \"negative\"\n",
    "        ]\n",
    "\n",
    "        context = \"## Knowledge Base\\n\"\n",
    "\n",
    "        if positive_knowledge:\n",
    "            context += \"### Positive Knowledge:\\n\"\n",
    "            context += (\n",
    "                \"This knowledge reflects principles that have consistently worked well to achieve the main goal.\\n\"\n",
    "                \"Use these as a primary guide when generating responses.\\n\"\n",
    "            )\n",
    "            context += \"\\n\".join(positive_knowledge) + \"\\n\\n\"\n",
    "\n",
    "        if general_knowledge:\n",
    "            context += \"### General Knowledge:\\n\"\n",
    "            context += (\n",
    "                \"This knowledge contains broader principles or patterns that can be applied to multiple scenarios.\\n\"\n",
    "                \"Use these when no specific positive knowledge applies.\\n\"\n",
    "            )\n",
    "            context += \"\\n\".join(general_knowledge) + \"\\n\\n\"\n",
    "\n",
    "        if negative_knowledge:\n",
    "            context += \"### Negative Knowledge:\\n\"\n",
    "            context += (\n",
    "                \"This knowledge reflects patterns or principles that did not work well or caused errors in the past.\\n\"\n",
    "                \"Avoid using these when generating responses.\\n\"\n",
    "            )\n",
    "            context += \"\\n\".join(negative_knowledge) + \"\\n\\n\"\n",
    "\n",
    "        if not (positive_knowledge or general_knowledge or negative_knowledge):\n",
    "            context += \"No knowledge entries available.\\n\"\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "    def update_from_feedback(self, feedback_result: FeedbackResult):\n",
    "        # Prune outdated knowledge\n",
    "        if feedback_result.prune_entries:\n",
    "            for entry_id in feedback_result.prune_entries:\n",
    "                if entry_id in self.entries:\n",
    "                    del self.entries[entry_id]\n",
    "\n",
    "        # Update existing knowledge\n",
    "        for update in feedback_result.update_entries:\n",
    "            if update.entry_id is not None and update.entry_id in self.entries:\n",
    "                self.entries[update.entry_id].content = update.content  # Use `content`\n",
    "                self.entries[update.entry_id].knowledge_type = update.knowledge_type\n",
    "                self.entries[update.entry_id].last_updated = datetime.now()\n",
    "\n",
    "        # Add new knowledge\n",
    "        for new_entry in feedback_result.new_entries:\n",
    "            entry = MemoryEntry(\n",
    "                content=new_entry.content,\n",
    "                knowledge_type=new_entry.knowledge_type,\n",
    "                entry_id=self.next_entry_id\n",
    "            )\n",
    "            self.entries[self.next_entry_id] = entry\n",
    "            self.next_entry_id += 1\n",
    "\n",
    "        self._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"Generated answer for the input query\")\n",
    "    explanation: str = Field(..., description=\"Explanation or reasoning behind the answer\")\n",
    "\n",
    "\n",
    "class FeedbackEntry(BaseModel):\n",
    "    entry_id: Optional[int] = Field(None, description=\"ID of the knowledge entry being updated (if applicable)\")\n",
    "    content: str = Field(..., description=\"Generalized knowledge or pattern to store\")\n",
    "    knowledge_type: str = Field(..., description=\"Type of knowledge: 'positive', 'negative', 'general'\")\n",
    "\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    prune_entries: List[int] = Field(default_factory=list, description=\"IDs of knowledge to prune\")\n",
    "    update_entries: List[FeedbackEntry] = Field(default_factory=list, description=\"Knowledge entries to update\")\n",
    "    new_entries: List[FeedbackEntry] = Field(default_factory=list, description=\"New knowledge entries to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, context: str):\n",
    "    system_prompt = \"\"\"You are a reasoning agent tasked with applying generalized knowledge to generate accurate and goal-aligned responses.\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    ## Task:\n",
    "    Use the knowledge provided in the context to generate the most accurate and goal-aligned answer for the query.\n",
    "\n",
    "    ## Query:\n",
    "    {input_query}\n",
    "\n",
    "    ## Context:\n",
    "    {context}\n",
    "\n",
    "    ### Instructions:\n",
    "    - Apply the most relevant generalized knowledge from the context.\n",
    "    - Avoid directly using specific input-output examples unless they represent generalizable principles.\n",
    "    - Ensure your response aligns with the main goal of the system.\n",
    "    - Penalize using incorrect or irrelevant knowledge while emphasizing positive and generalizable knowledge.\n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(main_goal: str, input_query: str, generated_answer: OperationalResult, correct_answer: str, context: str):\n",
    "    system_prompt = \"\"\"You are a feedback agent focused on improving the system's ability to achieve its main goal by analyzing the interaction and refining the knowledge base.\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    ## Main Goal:\n",
    "    {main_goal}\n",
    "\n",
    "    ## Query:\n",
    "    {input_query}\n",
    "\n",
    "    ## Generated Answer:\n",
    "    {generated_answer.answer}\n",
    "\n",
    "    ## Explanation of Generated Answer:\n",
    "    {generated_answer.explanation}\n",
    "\n",
    "    ## Correct Answer:\n",
    "    {correct_answer}\n",
    "\n",
    "    ## Current Knowledge Base Context:\n",
    "    {context}\n",
    "\n",
    "    ### Reinforcement Learning Approach:\n",
    "    Your role is to act like a reinforcement learning feedback system. Analyze the interaction and:\n",
    "    - Award points for positive contributions toward achieving the main goal.\n",
    "    - Penalize points for incorrect or irrelevant contributions.\n",
    "    - Extract general patterns, principles, or rules that align with the main goal.\n",
    "    - Focus on ensuring the system generalizes knowledge effectively to future tasks.\n",
    "\n",
    "    ### Tasks:\n",
    "\n",
    "    #### 1. Identify and Reward Positive Contributions\n",
    "    - Identify which parts of the generated answer align with the correct answer and the main goal.\n",
    "    - Highlight the knowledge items that contributed positively and explain why they worked.\n",
    "    - Mark these as **positive knowledge** with rewards to encourage their future use.\n",
    "\n",
    "    #### 2. Penalize and Correct Negative Contributions\n",
    "    - Identify which parts of the generated answer do not align with the correct answer or the main goal.\n",
    "    - Highlight knowledge items that caused errors or failed to contribute meaningfully.\n",
    "    - Provide an analysis of why they did not work and mark them as **negative knowledge** with penalties to discourage their use.\n",
    "\n",
    "    #### 3. Extract Generalizable Patterns\n",
    "    - Propose general patterns, transformations, or principles that can guide the system for similar queries.\n",
    "    - Focus on reusable rules rather than memorized input-output pairs.\n",
    "    - Add these as **general knowledge** for future guidance.\n",
    "\n",
    "    #### 4. Suggest Updates to Knowledge\n",
    "    - For existing knowledge:\n",
    "      - Recommend modifications to improve alignment with the main goal or make them more generalizable.\n",
    "    - For new knowledge:\n",
    "      - Propose generalized rules derived from the interaction to enhance future responses.\n",
    "\n",
    "    #### 5. Prune Knowledge\n",
    "    - Identify knowledge that is irrelevant, overly specific, or redundant.\n",
    "    - Suggest pruning such knowledge to maintain an efficient and effective knowledge base.\n",
    "\n",
    "    ### Examples of Feedback:\n",
    "    - If a knowledge item consistently helps achieve the main goal, award it positive points and refine it as needed.\n",
    "    - If a knowledge item introduces errors, penalize it and suggest corrections or pruning.\n",
    "    - If a pattern (e.g., \"Move initial consonants to the end and append 'ay'\") is generalizable, add it as new general knowledge.\n",
    "    - make the feedback detailed and actionable to guide the system's learning process effectively.\n",
    "    \n",
    "    ### Provide Detailed Feedback:\n",
    "    - Clearly explain the reasoning behind awarding or penalizing knowledge.\n",
    "    - Ensure all suggestions are actionable and aligned with the main goal.\n",
    "    - Focus on concise, generalizable insights to refine the system's ability to learn and improve.\n",
    "\n",
    "    ### Guidelines:\n",
    "    - Positive knowledge: Encourage reuse by awarding it.\n",
    "    - Negative knowledge: Penalize and discourage its use.\n",
    "    - General knowledge: Extract transferable principles for unseen data.\n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register the reasoners\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()\n",
    "\n",
    "def process_query(input_query: str, correct_answer: Optional[str] = None, main_goal: str = \"Learn patterns and transformations\",memory=None):\n",
    "    if memory is None:\n",
    "        memory = Memory()\n",
    "    context = memory.get_context()\n",
    "\n",
    "    # Operational Reasoner\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Feedback Reasoner\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            generated_answer=result,\n",
    "            correct_answer=correct_answer,\n",
    "            context=context\n",
    "        )\n",
    "        # Update memory\n",
    "        memory.update_from_feedback(feedback)\n",
    "\n",
    "        return {\"answer\": result.answer, \"feedback\": feedback}\n",
    "\n",
    "    return {\"answer\": result.answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: olleh | Correct: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: olleh | Correct: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: orldway | Correct: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: orldway | Correct: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: ythonpay | Correct: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: ythonpay | Correct: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: odecay | Correct: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: odecay | Correct: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: earnlay | Correct: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: earnlay | Correct: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: ellohay | Correct: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: ellohay | Correct: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: orldway | Correct: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: orldway | Correct: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: Ythonpay | Correct: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: Ythonpay | Correct: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: Odecay | Correct: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: Odecay | Correct: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: earnlay | Correct: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: earnlay | Correct: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: Ellohay | Correct: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: Ellohay | Correct: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: orldway | Correct: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: orldway | Correct: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: ythonpay | Correct: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: ythonpay | Correct: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: odecay | Correct: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: odecay | Correct: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory saved to memory_n2.json\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Memory saved to memory_n2.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: earnlay | Correct: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: earnlay | Correct: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\"query\": \"Transform 'hello'\", \"correct_answer\": \"Ellohay\"},\n",
    "    {\"query\": \"Transform 'world'\", \"correct_answer\": \"Orldway\"},\n",
    "    {\"query\": \"Transform 'python'\", \"correct_answer\": \"Ythonpay\"},\n",
    "    {\"query\": \"Transform 'code'\", \"correct_answer\": \"Odecay\"},\n",
    "    {\"query\": \"Transform 'learn'\", \"correct_answer\": \"Earnlay\"}\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(file_path=\"memory_n2.json\")\n",
    "    for _ in range(3):  # Iterate multiple times to reinforce learning\n",
    "        for example in training_examples:\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn to extract and apply transformation patterns\",\n",
    "                memory=memory\n",
    "            )\n",
    "            print(f\"Answer: {result['answer']} | Correct: {example['correct_answer']}\")\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on one epoch...\n",
      "\n",
      "System Answer: PIF (Python Is Fun) | Correct Answer: ysu\n",
      "System Answer: CISL | Correct Answer: osi\n",
      "System Answer: L&G | Correct Answer: enr\n",
      "System Answer: PracPerf | Correct Answer: rae\n",
      "System Answer: K = P | Correct Answer: nso\n",
      "System Answer: AI: The Future | Correct Answer: ishu\n",
      "System Answer: d2d | Correct Answer: are\n",
      "System Answer: Sci-mazing! | Correct Answer: csm\n",
      "System Answer: Lifelong Growth | Correct Answer: lee\n",
      "System Answer: Persist for success | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: py is fun! | Correct Answer: ysu\n",
      "System Answer: C.Life | Correct Answer: osi\n",
      "System Answer: L&G | Correct Answer: enr\n",
      "System Answer: pract-makes perf | Correct Answer: rae\n",
      "System Answer: K is P | Correct Answer: nso\n",
      "System Answer: A.I. = Future | Correct Answer: ishu\n",
      "System Answer: D2D (Data Drives Decisions) | Correct Answer: are\n",
      "System Answer: Sci Amz | Correct Answer: csm\n",
      "System Answer: Lifelong Growth | Correct Answer: lee\n",
      "System Answer: Persistence Pays Off | Correct Answer: eaf\n",
      "--------------------------------------------------\n",
      "Training on one epoch...\n",
      "\n",
      "System Answer: py is fun | Correct Answer: ysu\n",
      "System Answer: C0D3 L1F3 | Correct Answer: osi\n",
      "System Answer: Learn & Grow | Correct Answer: enr\n",
      "System Answer: PracMksPer | Correct Answer: rae\n",
      "System Answer: Knowledge = Power (K=P) | Correct Answer: nso\n",
      "System Answer: A.I. Future | Correct Answer: ishu\n",
      "System Answer: D3D: Data Drives Decisions | Correct Answer: are\n",
      "System Answer: Sci is Awe! | Correct Answer: csm\n",
      "System Answer: Lifelong Learning | Correct Answer: lee\n",
      "System Answer: Persist to Prosper | Correct Answer: eaf\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from builtins import print\n",
    "\n",
    "\n",
    "def transform_sentence(sentence,n=2):\n",
    "    n-=1\n",
    "    words = sentence.split()\n",
    "    transformed = ''.join(word[n] for word in words if len(word) >=n)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "# Training and testing data generation\n",
    "sentences = [\n",
    "    \"python is fun\",\n",
    "    \"code is life\",\n",
    "    \"learn and grow\",\n",
    "    \"practice makes perfect\",\n",
    "    \"knowledge is power\",\n",
    "    \"ai is the future\",\n",
    "    \"data drives decisions\",\n",
    "    \"science is amazing\",\n",
    "    \"always keep learning\",\n",
    "    \"perseverance pays off\",\n",
    "    \"learning is ongoing\",\n",
    "    \"practice brings mastery\",\n",
    "    \"knowledge fuels creativity\",\n",
    "    \"transform ideas daily\",\n",
    "    \"explore and create\",\n",
    "    \"analyze your potential\",\n",
    "    \"never stop growing\",\n",
    "    \"think outside boundaries\",\n",
    "    \"focus on improvement\",\n",
    "    \"believe in progress\"\n",
    "]\n",
    "\n",
    "nth_word=2\n",
    "# Generate examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": f\"Transform '{sentence}'\",\n",
    "        \"correct_answer\": transform_sentence(sentence,n=nth_word)\n",
    "    }\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "# Split examples into training and testing (10 each)\n",
    "training_examples = examples[:10]\n",
    "testing_examples = examples[10:]\n",
    "\n",
    "\n",
    "# Modified train_pattern_learner function\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(file_path=\"memory_n3.json\")  # Reset memory for fresh learning\n",
    "    for _ in range(3):\n",
    "        print(\"Training on one epoch...\\n\")\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            # print(f\"Training Example {i}: {example['query']}\")\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation rule that converts the input to output\",\n",
    "                memory=memory\n",
    "            )\n",
    "            print(f\"System Answer: {result.get('answer', 'No Answer')} | Correct Answer: {example['correct_answer']}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer to the input query based on current knowledge.\")\n",
    "    explanation: str = Field(..., description=\"The reasoning behind the answer.\")\n",
    "\n",
    "class RuleModification(BaseModel):\n",
    "    knowledge_id: int = Field(..., description=\"The knowledge item ID to modify.\")\n",
    "    new_content: str = Field(..., description=\"The new content for the knowledge item.\")\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    feedback: str = Field(..., description=\"Detailed feedback on the previous answer.\")\n",
    "    retain_knowledge_ids: List[int] = Field(\n",
    "        ..., description=\"IDs of knowledge items to retain as they are.\"\n",
    "    )\n",
    "    modify_knowledge: List[RuleModification] = Field(\n",
    "        default_factory=list, description=\"List of knowledge items to modify.\"\n",
    "    )\n",
    "    add_positive_knowledge: List[str] = Field(\n",
    "        default_factory=list, description=\"New positive knowledge items to add.\"\n",
    "    )\n",
    "    add_negative_knowledge: List[str] = Field(\n",
    "        default_factory=list, description=\"New negative knowledge items to add.\"\n",
    "    )\n",
    "    remove_knowledge_ids: List[int] = Field(\n",
    "        default_factory=list, description=\"IDs of knowledge items to remove.\"\n",
    "    )\n",
    "\n",
    "class KnowledgeItem(BaseModel):\n",
    "    id: int = Field(..., description=\"Unique identifier for the knowledge item.\")\n",
    "    content: str = Field(..., description=\"The content of the knowledge item.\")\n",
    "    type: str = Field(..., description=\"Type of knowledge: 'positive' or 'negative'.\")\n",
    "    created_at: datetime = Field(default_factory=datetime.now, description=\"Creation timestamp.\")\n",
    "    last_updated: datetime = Field(default_factory=datetime.now, description=\"Last update timestamp.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"memory.json\"):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.positive_knowledge: List[KnowledgeItem] = []\n",
    "        self.negative_knowledge: List[KnowledgeItem] = []\n",
    "        self.next_knowledge_id = 1\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        data = json.loads(self.file_path.read_text())\n",
    "        self.next_knowledge_id = data.get('next_knowledge_id', 1)\n",
    "        self.positive_knowledge = [KnowledgeItem(**item) for item in data.get('positive_knowledge', [])]\n",
    "        self.negative_knowledge = [KnowledgeItem(**item) for item in data.get('negative_knowledge', [])]\n",
    "\n",
    "    def _save(self):\n",
    "        data = {\n",
    "            'next_knowledge_id': self.next_knowledge_id,\n",
    "            'positive_knowledge': [item.model_dump() for item in self.positive_knowledge],\n",
    "            'negative_knowledge': [item.model_dump() for item in self.negative_knowledge],\n",
    "        }\n",
    "        # Ensure datetime objects are serialized as strings\n",
    "        self.file_path.write_text(json.dumps(data, default=str, indent=2))\n",
    "\n",
    "    def get_positive_knowledge_context(self) -> str:\n",
    "        if not self.positive_knowledge:\n",
    "            return \"No positive knowledge available.\"\n",
    "        return \"Positive Knowledge (use IDs to refer):\\n\" + \"\\n\".join(\n",
    "            f\"{item.id}. {item.content}\" for item in self.positive_knowledge\n",
    "        )\n",
    "\n",
    "    def get_negative_knowledge_context(self) -> str:\n",
    "        if not self.negative_knowledge:\n",
    "            return \"No negative knowledge available.\"\n",
    "        return \"Negative Knowledge (use IDs to refer):\\n\" + \"\\n\".join(\n",
    "            f\"{item.id}. {item.content}\" for item in self.negative_knowledge\n",
    "        )\n",
    "\n",
    "    def update_from_feedback(self, feedback: FeedbackResult):\n",
    "        # Retain specified knowledge items\n",
    "        retain_ids = set(feedback.retain_knowledge_ids)\n",
    "        self.positive_knowledge = [item for item in self.positive_knowledge if item.id in retain_ids]\n",
    "        self.negative_knowledge = [item for item in self.negative_knowledge if item.id in retain_ids]\n",
    "\n",
    "        # Modify existing knowledge\n",
    "        if feedback.modify_knowledge:\n",
    "            for mod in feedback.modify_knowledge:\n",
    "                # Search in positive and negative knowledge\n",
    "                for item in self.positive_knowledge + self.negative_knowledge:\n",
    "                    if item.id == mod.knowledge_id:\n",
    "                        item.content = mod.new_content\n",
    "                        item.last_updated = datetime.now()\n",
    "                        break\n",
    "\n",
    "        # Remove knowledge items\n",
    "        if feedback.remove_knowledge_ids:\n",
    "            self.positive_knowledge = [item for item in self.positive_knowledge if item.id not in feedback.remove_knowledge_ids]\n",
    "            self.negative_knowledge = [item for item in self.negative_knowledge if item.id not in feedback.remove_knowledge_ids]\n",
    "\n",
    "        # Add new positive knowledge\n",
    "        if feedback.add_positive_knowledge:\n",
    "            for content in feedback.add_positive_knowledge:\n",
    "                new_item = KnowledgeItem(\n",
    "                    id=self.next_knowledge_id,\n",
    "                    content=content,\n",
    "                    type=\"positive\",\n",
    "                )\n",
    "                self.positive_knowledge.append(new_item)\n",
    "                self.next_knowledge_id += 1\n",
    "\n",
    "        # Add new negative knowledge\n",
    "        if feedback.add_negative_knowledge:\n",
    "            for content in feedback.add_negative_knowledge:\n",
    "                new_item = KnowledgeItem(\n",
    "                    id=self.next_knowledge_id,\n",
    "                    content=content,\n",
    "                    type=\"negative\",\n",
    "                )\n",
    "                self.negative_knowledge.append(new_item)\n",
    "                self.next_knowledge_id += 1\n",
    "\n",
    "        self._save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, positive_context: str, negative_context: str):\n",
    "    system_prompt = \"\"\"You are an intelligent agent designed to provide accurate and consistent answers based on generalized knowledge.\n",
    "Apply the positive knowledge effectively and avoid using knowledge items classified as negative.\n",
    "Focus on transferring general principles to solve new queries.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Query: {input_query}\n",
    "\n",
    "{positive_context}\n",
    "\n",
    "{negative_context}\n",
    "\n",
    "Important:\n",
    "- Use the positive knowledge items to guide your answer.\n",
    "- Avoid using any strategies or patterns mentioned in the negative knowledge items.\n",
    "- Do not memorize specific input-output pairs; instead, apply general principles.\n",
    "- Provide your answer that aligns with the main goal.\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "# @brain_client.reasoner(schema=FeedbackResult)\n",
    "# def feedback_reasoner(main_goal: str, input_query: str, answer: OperationalResult, correct_answer: str, positive_context: str, negative_context: str):\n",
    "#     system_prompt = f\"\"\"You are a sophisticated learning feedback agent focused on extracting and refining knowledge to achieve the main goal.\n",
    "\n",
    "# MAIN GOAL: {main_goal}\n",
    "\n",
    "# Your tasks:\n",
    "# 1. Analyze the differences between the system's answer and the correct answer.\n",
    "# 2. Understand ad give feeddback on the system's reasoning based on the main goal\n",
    "# 2. Extract generalized, transferable knowledge that aligns with the main goal.\n",
    "# 3. Identify what worked (positive knowledge) and what didn't (negative knowledge).\n",
    "# 4. Suggest modifications to existing knowledge or propose new knowledge items.\n",
    "# 5. Ensure that the extracted knowledge enhances the system's ability to generalize to unseen data.\n",
    "\n",
    "# Core Analysis Principles:\n",
    "# - Focus on underlying principles and patterns.\n",
    "# - Separate positive insights from negative ones.\n",
    "# - Ensure knowledge is goal-oriented and transferable.\"\"\"\n",
    "\n",
    "#     user_prompt = f\"\"\"DEEP LEARNING ANALYSIS:\n",
    "\n",
    "# GOAL TO ACHIEVE: {main_goal}\n",
    "\n",
    "# Current Learning Instance:\n",
    "# Input: {input_query}\n",
    "# ---\n",
    "# System Output: {answer.answer}\n",
    "# System Explanation: {answer.explanation}\n",
    "# ----\n",
    "# Expected Output: {correct_answer}\n",
    "\n",
    "# Existing Positive Knowledge:\n",
    "# {positive_context}\n",
    "\n",
    "# Existing Negative Knowledge:\n",
    "# {negative_context}\n",
    "\n",
    "# Instructions:\n",
    "# - Use the IDs provided to refer to specific knowledge items.\n",
    "# - Do not memorize specific input-output pairs.\n",
    "# - Provide feedback in terms of general principles and patterns.\n",
    "# - Understand ad give feeddback on the system's reasoning based on the main goal\n",
    "\n",
    "# Perform Deep Analysis:\n",
    "# 1. What fundamental understanding would help achieve the goal here?\n",
    "# 2. What deeper patterns are revealed when comparing outputs?\n",
    "# 3. What core principles would improve goal achievement?\n",
    "# 4. What essential knowledge is missing from our current positive knowledge?\n",
    "# 5. What negative knowledge should be added based on what did not work?\n",
    "\n",
    "# Provide:\n",
    "# 1. Rich Analysis: Detailed feedback on what can be learned regarding the main goal.\n",
    "# 2. Retain Knowledge IDs: List IDs of positive and negative knowledge items that should be retained.\n",
    "# 3. Knowledge Modifications: List of modifications in the format [[knowledge_id, \"enhanced or corrected content\"]] for existing knowledge items to modify.\n",
    "# 4. New Positive Knowledge: Add detailed new positive knowledge items that capture essential goal-relevant information.\n",
    "# 5. New Negative Knowledge: Add detailed new negative knowledge items that capture what should be avoided.\n",
    "# 6. Remove Knowledge IDs: List IDs of knowledge items that should be removed.\n",
    "# 7. make the knowledge detailed and actionable to guide the system's learning process effectively.\n",
    "# 8. You will add new knowledge items if you see that the existing knowledge is not enough to achieve the main goal for future similar (Not same) queries.\n",
    "# 9. You will remove exieting knowledge if you think it is wrong to achieve the main goal. But note if you think it might be relevant for future  similar (Not same) queries, you can keep it.\n",
    "# 10. You will modify existing knowledge if you think it is not enough to achieve the main goal for future  similar (Not same) queries.\n",
    "# 11. You will retain existing knowledge if you think it is important to achieve the main goal for future similar (Not same) queries.\n",
    "\n",
    "# Focus Areas:\n",
    "# - Deep understanding over surface patterns.\n",
    "# - Core principles over specific solutions.\n",
    "# - Transferable knowledge over contextual details.\n",
    "# - Fundamental concepts over specific applications.\n",
    "# - Goal achievement mechanisms over input-output pairs.\n",
    "\n",
    "# - If something is working, provide positive feedback to reinforce it.\n",
    "# - If something is not working, provide negative feedback to suppress it.\n",
    "# \"\"\"\n",
    "\n",
    "#     return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(\n",
    "    main_goal: str,\n",
    "    input_query: str,\n",
    "    answer: OperationalResult,\n",
    "    correct_answer: str,\n",
    "    positive_context: str,\n",
    "    negative_context: str\n",
    "):\n",
    "    system_prompt = f\"\"\"You are a sophisticated learning feedback agent dedicated to extracting and refining knowledge to achieve the main goal.\n",
    "\n",
    "MAIN GOAL: {main_goal}\n",
    "\n",
    "Your Objectives:\n",
    "1. Analyze the differences between the system's answer and the correct answer.\n",
    "2. Provide feedback on the system's reasoning in relation to the main goal.\n",
    "3. Extract generalized, transferable knowledge that aligns with the main goal.\n",
    "4. Identify what worked (positive knowledge) and what didn't work (negative knowledge).\n",
    "5. Suggest modifications to existing knowledge or propose new knowledge items.\n",
    "6. Enhance the system's ability to generalize to unseen data through the extracted knowledge.\n",
    "\n",
    "Core Principles:\n",
    "- Focus on underlying principles and patterns.\n",
    "- Separate positive insights from negative ones.\n",
    "- Ensure all knowledge is goal-oriented and transferable.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"# DEEP LEARNING ANALYSIS\n",
    "\n",
    "**GOAL TO ACHIEVE:** {main_goal}\n",
    "\n",
    "## Current Learning Instance:\n",
    "- **Input Query:** {input_query}\n",
    "- **System Output:** {answer.answer}\n",
    "- **System Explanation:** {answer.explanation}\n",
    "- **Expected Output:** {correct_answer}\n",
    "\n",
    "## Existing Knowledge:\n",
    "### Positive Knowledge:\n",
    "{positive_context}\n",
    "\n",
    "### Negative Knowledge:\n",
    "{negative_context}\n",
    "\n",
    "## Your Tasks:\n",
    "\n",
    "### 1. Analysis:\n",
    "- Compare the system's output with the expected output.\n",
    "- Analyze the system's reasoning in relation to the main goal.\n",
    "- Identify fundamental understandings that would help achieve the goal.\n",
    "- Reveal deeper patterns when comparing outputs.\n",
    "- Determine core principles that would improve goal achievement.\n",
    "\n",
    "### 2. Feedback:\n",
    "- Provide detailed feedback on what can be learned regarding the main goal.\n",
    "- Highlight what worked (positive aspects) and what didn't work (negative aspects).\n",
    "- Focus on general principles and patterns, not specific input-output pairs.\n",
    "\n",
    "### 3. Knowledge Management:\n",
    "- **Retain Knowledge**: List IDs of positive and negative knowledge items that should be retained as they are.\n",
    "- **Modify Knowledge**: Suggest modifications to existing knowledge items that need enhancement or correction. Provide in the format:\n",
    "[[knowledge_id, \"enhanced or corrected content\"]]\n",
    "- **Add New Knowledge**:\n",
    "- **New Positive Knowledge**: Add detailed new positive knowledge items that capture essential goal-relevant information.\n",
    "- **New Negative Knowledge**: Add detailed new negative knowledge items that capture what should be avoided.\n",
    "- **Remove Knowledge**: List IDs of knowledge items that should be removed if they are incorrect or unhelpful toward achieving the main goal.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- **Use the provided IDs** to refer to specific knowledge items.\n",
    "- **Do not memorize specific input-output pairs**; focus on generalizing principles to future similar queries.\n",
    "- **Make the knowledge detailed and actionable** to effectively guide the system's learning process.\n",
    "- **Add new knowledge** if existing knowledge is insufficient for future similar (not identical) queries.\n",
    "- **Remove existing knowledge** only if it is incorrect and not relevant for future similar queries.\n",
    "- **Modify existing knowledge** if it needs enhancement to achieve the main goal for future similar queries.\n",
    "- **Retain existing knowledge** if it is important for achieving the main goal in future similar queries.\n",
    "\n",
    "## Focus Areas:\n",
    "\n",
    "- Emphasize **deep understanding** over surface patterns.\n",
    "- Prioritize **core principles** over specific solutions.\n",
    "- Ensure knowledge is **transferable** to new, unseen data.\n",
    "- Focus on **fundamental concepts** over specific applications.\n",
    "- Concentrate on mechanisms that achieve the **main goal** over specific input-output pairs.\n",
    "\n",
    "- If something is working, **provide positive feedback** to reinforce it.\n",
    "- If something is not working, **provide negative feedback** to suppress it.\n",
    "\n",
    "Important Notes:\n",
    "\n",
    "Ensure that all parts of the output are filled appropriately.\n",
    "Include all reasoning and analysis within the \"feedback\" field.\n",
    "Be concise but thorough in your feedback and knowledge suggestions.\n",
    "Do not include any extraneous text outside of the specified output format.\n",
    "Focus on extracting general principles that will help improve future performance toward achieving the main goal.\n",
    "\"\"\"\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming brain_client is already defined and set up\n",
    "# You may need to import or define brain_client as per your environment\n",
    "# For the purpose of this code, we assume brain_client is available\n",
    "\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(input_query: str, correct_answer: Optional[str] = None, \n",
    "                  main_goal: str = \"Learn to provide accurate and consistent responses\",\n",
    "                  memory: Optional[Memory] = None):\n",
    "    if memory is None:\n",
    "        memory = Memory()\n",
    "    positive_context = memory.get_positive_knowledge_context()\n",
    "    negative_context = memory.get_negative_knowledge_context()\n",
    "\n",
    "    # Get answer using current positive and negative knowledge\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query,\n",
    "        positive_context=positive_context,\n",
    "        negative_context=negative_context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Get feedback and evolve knowledge\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            answer=result,\n",
    "            correct_answer=correct_answer,\n",
    "            positive_context=positive_context,\n",
    "            negative_context=negative_context\n",
    "        )\n",
    "        # Update memory based on feedback\n",
    "        memory.update_from_feedback(feedback)\n",
    "        # We let the LLM decide what knowledge to remove or keep\n",
    "        return {\"answer\": result.answer, \"feedback\": feedback}\n",
    "    \n",
    "    return {\"answer\": result.answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "System Answer: ellohay | Correct Answer: Ellohay\n",
      "--------------------------------------------------\n",
      "System Answer: orldway | Correct Answer: Orldway\n",
      "--------------------------------------------------\n",
      "System Answer: onpythay | Correct Answer: Ythonpay\n",
      "--------------------------------------------------\n",
      "System Answer: odecay | Correct Answer: Odecay\n",
      "--------------------------------------------------\n",
      "System Answer: earnlay | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "Epoch 2\n",
      "System Answer: ellohay | Correct Answer: Ellohay\n",
      "--------------------------------------------------\n",
      "System Answer: orldway | Correct Answer: Orldway\n",
      "--------------------------------------------------\n",
      "System Answer: onpythay | Correct Answer: Ythonpay\n",
      "--------------------------------------------------\n",
      "System Answer: odecay | Correct Answer: Odecay\n",
      "--------------------------------------------------\n",
      "System Answer: earnlway | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "Epoch 3\n",
      "System Answer: ellohay | Correct Answer: Ellohay\n",
      "--------------------------------------------------\n",
      "System Answer: orldway | Correct Answer: Orldway\n",
      "--------------------------------------------------\n",
      "System Answer: ythonpay | Correct Answer: Ythonpay\n",
      "--------------------------------------------------\n",
      "System Answer: c0de | Correct Answer: Odecay\n",
      "--------------------------------------------------\n",
      "System Answer: Learn | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "Epoch 4\n",
      "System Answer: hElLo | Correct Answer: Ellohay\n",
      "--------------------------------------------------\n",
      "System Answer: worlday | Correct Answer: Orldway\n",
      "--------------------------------------------------\n",
      "System Answer: pythonic | Correct Answer: Ythonpay\n",
      "--------------------------------------------------\n",
      "System Answer: odecay | Correct Answer: Odecay\n",
      "--------------------------------------------------\n",
      "System Answer: earnlay | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "Epoch 5\n",
      "System Answer: ellohay | Correct Answer: Ellohay\n",
      "--------------------------------------------------\n",
      "System Answer: orldway | Correct Answer: Orldway\n",
      "--------------------------------------------------\n",
      "System Answer: ythonpay | Correct Answer: Ythonpay\n",
      "--------------------------------------------------\n",
      "System Answer: odecay | Correct Answer: Odecay\n",
      "--------------------------------------------------\n",
      "System Answer: earnlay | Correct Answer: Earnlay\n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"query\": \"Transform 'hello'\",\n",
    "        \"correct_answer\": \"Ellohay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'world'\",\n",
    "        \"correct_answer\": \"Orldway\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'python'\",\n",
    "        \"correct_answer\": \"Ythonpay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'code'\",\n",
    "        \"correct_answer\": \"Odecay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'learn'\",\n",
    "        \"correct_answer\": \"Earnlay\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(\"mem_aa.json\")\n",
    "    # memory.positive_knowledge = []\n",
    "    # memory.negative_knowledge = []\n",
    "    # memory.next_knowledge_id = 1\n",
    "    memory._save()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation pattern that converts the input to output\",\n",
    "                memory=memory\n",
    "            )\n",
    "            # print(f\"Query: {example['query']}\")\n",
    "            print(f\"System Answer: {result['answer']} | Correct Answer: {example['correct_answer']}\")\n",
    "            # print(f\"Feedback: {result['feedback']}\")\n",
    "            print(\"-\" * 50)\n",
    "        print(\"=\" * 50)\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "System Answer: Python is enjoyable. | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: L&G | Correct Answer: lag\n",
      "System Answer: pmp | Correct Answer: pmp\n",
      "System Answer: k.i.p. | Correct Answer: kip\n",
      "System Answer: ai | Correct Answer: aitf\n",
      "System Answer: dd | Correct Answer: ddd\n",
      "System Answer: sim | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: PPO | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "System Answer: PIF | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: lag | Correct Answer: lag\n",
      "System Answer: PM | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: ai-f-t | Correct Answer: aitf\n",
      "System Answer: dd | Correct Answer: ddd\n",
      "System Answer: siA | Correct Answer: sia\n",
      "System Answer: akl | Correct Answer: akl\n",
      "System Answer: PPO | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "System Answer: PIF | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: LAG | Correct Answer: lag\n",
      "System Answer: PMP | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: aiitf | Correct Answer: aitf\n",
      "System Answer: DDD | Correct Answer: ddd\n",
      "System Answer: SIA | Correct Answer: sia\n",
      "System Answer: akl | Correct Answer: akl\n",
      "System Answer: PpO | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "System Answer: pif | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: lag | Correct Answer: lag\n",
      "System Answer: pm | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: ai_is_the_future | Correct Answer: aitf\n",
      "System Answer: ddd | Correct Answer: ddd\n",
      "System Answer: sia | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: PPO | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "System Answer: pif | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: lag | Correct Answer: lag\n",
      "System Answer: pmpe | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: aiif | Correct Answer: aitf\n",
      "System Answer: ddd | Correct Answer: ddd\n",
      "System Answer: siam | Correct Answer: sia\n",
      "System Answer: akl | Correct Answer: akl\n",
      "System Answer: ppo | Correct Answer: ppo\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from builtins import print\n",
    "\n",
    "\n",
    "def transform_sentence(sentence,n=2):\n",
    "    n-=1\n",
    "    words = sentence.split()\n",
    "    transformed = ''.join(word[n] for word in words if len(word) >=n)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "# Training and testing data generation\n",
    "sentences = [\n",
    "    \"python is fun\",\n",
    "    \"code is life\",\n",
    "    \"learn and grow\",\n",
    "    \"practice makes perfect\",\n",
    "    \"knowledge is power\",\n",
    "    \"ai is the future\",\n",
    "    \"data drives decisions\",\n",
    "    \"science is amazing\",\n",
    "    \"always keep learning\",\n",
    "    \"perseverance pays off\",\n",
    "    \"learning is ongoing\",\n",
    "    \"practice brings mastery\",\n",
    "    \"knowledge fuels creativity\",\n",
    "    \"transform ideas daily\",\n",
    "    \"explore and create\",\n",
    "    \"analyze your potential\",\n",
    "    \"never stop growing\",\n",
    "    \"think outside boundaries\",\n",
    "    \"focus on improvement\",\n",
    "    \"believe in progress\"\n",
    "]\n",
    "\n",
    "nth_word=1\n",
    "# Generate examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": f\"Transform '{sentence}'\",\n",
    "        \"correct_answer\": transform_sentence(sentence,n=nth_word)\n",
    "    }\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "# Split examples into training and testing (10 each)\n",
    "training_examples = examples[:10]\n",
    "testing_examples = examples[10:]\n",
    "\n",
    "\n",
    "# Modified train_pattern_learner function\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(\"mem3.json\")\n",
    "    memory.positive_knowledge = []\n",
    "    memory.negative_knowledge = []\n",
    "    memory.next_knowledge_id = 1\n",
    "    memory._save()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation rule that converts the input to output and return the correct output\",\n",
    "                memory=memory\n",
    "            )\n",
    "            \n",
    "            print(f\"System Answer: {result.get('answer', 'No Answer')} | Correct Answer: {example['correct_answer']}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "System Answer: Python is enjoyable | Correct Answer: pif\n",
      "System Answer: \"code is life\" can be transformed to \"life is code\". | Correct Answer: cil\n",
      "System Answer: L&G | Correct Answer: lag\n",
      "System Answer: Skill development through repetition | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: AI-Future | Correct Answer: aitf\n",
      "System Answer: D3 | Correct Answer: ddd\n",
      "System Answer: SIA (Science Is Amazing) | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: PPOP | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "System Answer: PYTHON = Fun | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: L&G | Correct Answer: lag\n",
      "System Answer: PMP (Practice Makes Perfect) | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: AI is the future. | Correct Answer: aitf\n",
      "System Answer: D3 | Correct Answer: ddd\n",
      "System Answer: SIA (Science Is Amazing) | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: Perseverance leads to success. | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "System Answer: PIF | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: L&G | Correct Answer: lag\n",
      "System Answer: PMP | Correct Answer: pmp\n",
      "System Answer: K.I.P. | Correct Answer: kip\n",
      "System Answer: AIITF | Correct Answer: aitf\n",
      "System Answer: D3 | Correct Answer: ddd\n",
      "System Answer: Science is awesome! | Correct Answer: sia\n",
      "System Answer: Always keep learning. | Correct Answer: akl\n",
      "System Answer: Persistence yields results | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "System Answer: python is fun! | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: LEARN & GROW | Correct Answer: lag\n",
      "System Answer: PMP | Correct Answer: pmp\n",
      "System Answer: K = P | Correct Answer: kip\n",
      "System Answer: AI is the future. | Correct Answer: aitf\n",
      "System Answer: D3D (Data Drives Decisions) | Correct Answer: ddd\n",
      "System Answer: SIA (Science Is Amazing) | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: PPO (Perseverance Pays Off) | Correct Answer: ppo\n",
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "System Answer: python is fun | Correct Answer: pif\n",
      "System Answer: CIL | Correct Answer: cil\n",
      "System Answer: LAG | Correct Answer: lag\n",
      "System Answer: PMP | Correct Answer: pmp\n",
      "System Answer: KIP | Correct Answer: kip\n",
      "System Answer: AIITF | Correct Answer: aitf\n",
      "System Answer: D3D | Correct Answer: ddd\n",
      "System Answer: SIA | Correct Answer: sia\n",
      "System Answer: AKL | Correct Answer: akl\n",
      "System Answer: PPPO | Correct Answer: ppo\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from builtins import print\n",
    "import random\n",
    "\n",
    "def transform_sentence(sentence, n=2):\n",
    "    n -= 1\n",
    "    words = sentence.split()\n",
    "    transformed = ''.join(word[n] for word in words if len(word) > n)\n",
    "    return transformed\n",
    "\n",
    "# Training and testing data generation\n",
    "sentences = [\n",
    "    \"python is fun\",\n",
    "    \"code is life\",\n",
    "    \"learn and grow\",\n",
    "    \"practice makes perfect\",\n",
    "    \"knowledge is power\",\n",
    "    \"ai is the future\",\n",
    "    \"data drives decisions\",\n",
    "    \"science is amazing\",\n",
    "    \"always keep learning\",\n",
    "    \"perseverance pays off\",\n",
    "    \"learning is ongoing\",\n",
    "    \"practice brings mastery\",\n",
    "    \"knowledge fuels creativity\",\n",
    "    \"transform ideas daily\",\n",
    "    \"explore and create\",\n",
    "    \"analyze your potential\",\n",
    "    \"never stop growing\",\n",
    "    \"think outside boundaries\",\n",
    "    \"focus on improvement\",\n",
    "    \"believe in progress\"\n",
    "]\n",
    "\n",
    "nth_word = 1\n",
    "m_shot = 0  # Number of shot examples\n",
    "\n",
    "# Generate examples with m-shot context\n",
    "examples = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    shot_examples = random.sample([s for s in sentences if s != sentence], min(m_shot, len(sentences) - 1))  # Select random m-shot examples excluding the current sentence\n",
    "    shots = \"\\n\".join(\n",
    "        [f\"If \\\"{s}\\\" is transformed to \\\"{transform_sentence(s, n=nth_word)}\\\"\" for s in shot_examples]\n",
    "    )\n",
    "\n",
    "    query = f\"{shots}\\nthen what is \\\"{sentence}\\\" transformed to?\" if shots else f\"What is \\\"{sentence}\\\" transformed to?\"\n",
    "    examples.append(\n",
    "        {\n",
    "            \"query\": query,\n",
    "            \"correct_answer\": transform_sentence(sentence, n=nth_word)\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Split examples into training and testing (10 each)\n",
    "training_examples = examples[:10]\n",
    "testing_examples = examples[10:]\n",
    "\n",
    "# Modified train_pattern_learner function\n",
    "def train_pattern_learner():\n",
    "    memory = Memory(\"mem_0_shot_1_shift.json\")\n",
    "    memory.positive_knowledge = []\n",
    "    memory.negative_knowledge = []\n",
    "    memory.next_knowledge_id = 1\n",
    "    memory._save()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation rule that converts the input to output and return the correct output\",\n",
    "                memory=memory\n",
    "            )\n",
    "\n",
    "            print(f\"System Answer: {result.get('answer', 'No Answer')} | Correct Answer: {example['correct_answer']}\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
