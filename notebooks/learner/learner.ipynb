{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from typing import List, Union\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print\n",
    "\n",
    "from brain.sdk import BrainClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_client = BrainClient(\"http://127.0.0.1:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer to the input query\")\n",
    "\n",
    "class RuleModification(BaseModel):\n",
    "    rule_number: int = Field(..., description=\"The rule number to modify\")\n",
    "    new_content: str = Field(..., description=\"The new content for the rule\")\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    feedback: str = Field(..., description=\"Feedback on the previous answer\")\n",
    "    keep_rules: List[int] = Field(..., description=\"Rule numbers to keep\")\n",
    "    modify_rules: List[RuleModification] = Field(default_factory=list, description=\"Rules to modify\")\n",
    "    new_rules: List[str] = Field(default_factory=list, description=\"New rules to add\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import json\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, content: str, rule_id: int):\n",
    "        self.content = content\n",
    "        self.rule_id = rule_id\n",
    "        self.created_at = datetime.now()\n",
    "        self.last_updated = datetime.now()\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"memory.json\"):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.rules: Dict[int, Rule] = {}\n",
    "        self.next_rule_id = 1\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        data = json.loads(self.file_path.read_text())\n",
    "        self.next_rule_id = data['next_rule_id']\n",
    "        self.rules = {\n",
    "            int(rule_id): Rule(\n",
    "                content=rule['content'],\n",
    "                rule_id=int(rule_id)\n",
    "            )\n",
    "            for rule_id, rule in data['rules'].items()\n",
    "        }\n",
    "\n",
    "    def _save(self):\n",
    "        data = {\n",
    "            'next_rule_id': self.next_rule_id,\n",
    "            'rules': {\n",
    "                str(rule_id): {\n",
    "                    'content': rule.content,\n",
    "                }\n",
    "                for rule_id, rule in self.rules.items()\n",
    "            }\n",
    "        }\n",
    "        self.file_path.write_text(json.dumps(data, indent=2))\n",
    "\n",
    "    def get_rules_context(self) -> str:\n",
    "        # if not self.rules:\n",
    "        #     return \"No existing rules.\"\n",
    "        \n",
    "        return \"Current rules:\\n\" + \"\\n\".join(\n",
    "            f\"{rule.rule_id}. {rule.content}\"\n",
    "            for rule in sorted(self.rules.values(), key=lambda x: x.rule_id)\n",
    "        )\n",
    "\n",
    "    def update_from_feedback(self, feedback: FeedbackResult):\n",
    "        # Convert current rules to set for easier processing\n",
    "        current_rule_ids = set(self.rules.keys())\n",
    "        keep_rules = set(feedback.keep_rules)\n",
    "        \n",
    "        # Remove rules not in keep_rules\n",
    "        rules_to_remove = current_rule_ids - keep_rules\n",
    "        if rules_to_remove:\n",
    "            for rule_id in rules_to_remove:\n",
    "                self.rules.pop(rule_id, None)\n",
    "\n",
    "        # Modify existing rules\n",
    "        if feedback.modify_rules:\n",
    "            for modification in feedback.modify_rules:\n",
    "                if modification.rule_number in self.rules:\n",
    "                    self.rules[modification.rule_number].content = modification.new_content\n",
    "                    self.rules[modification.rule_number].last_updated = datetime.now()\n",
    "\n",
    "        # Add new rules\n",
    "        if feedback.new_rules:\n",
    "            for content in feedback.new_rules:\n",
    "                rule = Rule(content=content, rule_id=self.next_rule_id)\n",
    "                self.rules[self.next_rule_id] = rule\n",
    "                self.next_rule_id += 1\n",
    "\n",
    "        self._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, context: str):\n",
    "    system_prompt = \"\"\"You are an agent designed to provide answers based on learned rules.\n",
    "Apply the rules wisely - not every rule needs to be used for every answer.\n",
    "You are an agent that uses knowledge to generate accurate, generalized answers. \n",
    "Focus on principles and patterns, not specific memorization. Use the context provided to:\n",
    "1. Identify underlying patterns.\n",
    "2. Apply generalized knowledge to new inputs.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Query: {input_query}\n",
    "\n",
    "{context}\n",
    "\n",
    "Using these rules as guidelines, provide your answer:\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(main_goal: str, input_query: str, answer: str, correct_answer: str, context: str):\n",
    "    system_prompt = f\"\"\"You are a learning feedback agent focused on extracting deep insights aligned with a specific goal.\n",
    "\n",
    "MAIN GOAL: {main_goal}\n",
    "\n",
    "Your purpose is to help the system learn HOW to achieve this goal by:\n",
    "1. Analyzing differences between given answers and correct answers\n",
    "2. Extracting detailed knowledge that helps achieve the main goal\n",
    "3. Creating comprehensive rules that guide future responses\n",
    "4. Building a knowledge base focused on the goal's requirements\n",
    "\n",
    "Core Analysis Principles:\n",
    "- Extract general patterns, not specific solutions\n",
    "- Look for underlying principles that achieve the goal\n",
    "- Focus on knowledge that transfers to new situations\n",
    "- Identify what knowledge would help achieve better answers\n",
    "- Consider what deep understanding is missing\n",
    "- Think about what fundamental concepts would improve performance\n",
    "\n",
    "Rules/Knowledge Requirements:\n",
    "- Must directly relate to achieving the main goal\n",
    "- Should be detailed and comprehensive\n",
    "- Must be generally applicable\n",
    "- Should capture underlying principles\n",
    "- Must focus on transferable knowledge\n",
    "- Should build on existing understanding\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"DEEP LEARNING ANALYSIS:\n",
    "\n",
    "GOAL TO ACHIEVE: {main_goal}\n",
    "\n",
    "Current Learning Instance:\n",
    "Input: {input_query}\n",
    "Current Output: {answer}\n",
    "Expected Output: {correct_answer}\n",
    "\n",
    "Existing Knowledge Base:\n",
    "{context}\n",
    "\n",
    "Perform Deep Analysis:\n",
    "1. What fundamental understanding would help achieve the goal here?\n",
    "2. What deeper patterns reveal themselves when comparing outputs?\n",
    "3. What core principles would improve goal achievement?\n",
    "4. What essential knowledge is missing from our current rules?\n",
    "5. What broader understanding would help with similar goals?\n",
    "\n",
    "Provide:\n",
    "1. Rich Analysis: Detailed feedback about what we can learn regarding our goal\n",
    "2. Retained Knowledge: List numbers of rules that contain valid, goal-relevant principles\n",
    "3. Knowledge Updates: List [[rule_number, \"enhanced knowledge or principle\"]]\n",
    "4. New Understanding: Add detailed new rules that capture essential goal-relevant knowledge\n",
    "\n",
    "Focus Areas:\n",
    "- Deep understanding over surface patterns\n",
    "- Core principles over specific solutions\n",
    "- Transferable knowledge over contextual details\n",
    "- Fundamental concepts over specific applications\n",
    "- Goal achievement mechanisms over input-output pairs\n",
    "Your goal is to help the system learn to achieve its main goal by analyzing successes and failures.\n",
    "- Identify positive patterns that led to correct answers.\n",
    "- Identify negative patterns or gaps that caused failures.\n",
    "- Provide insights to refine knowledge for future queries.\n",
    "- Focus on creating rules or principles that generalize well.\n",
    "\n",
    "\n",
    "- If something is working give positive feedback so that the system can learn from it\n",
    "- If something is not working give negative feedback so that the system can learn from it\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(input_query: str, correct_answer: Optional[str] = None, \n",
    "                 main_goal: str = \"Learn to provide accurate and consistent responses\"):\n",
    "    memory = Memory()\n",
    "    context = memory.get_rules_context()\n",
    "    # Get answer using current rules\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Get feedback and evolve rules\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            answer=result.answer,\n",
    "            correct_answer=correct_answer,\n",
    "            context=context\n",
    "        )\n",
    "        # Update memory based on feedback\n",
    "        memory.update_from_feedback(feedback)\n",
    "        \n",
    "        return {\"answer\": result.answer, \"feedback\": feedback}\n",
    "    \n",
    "    return {\"answer\": result.answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = \"What is the capital of France?\"\n",
    "# result1 = process_query(\n",
    "#     input_query=query1,\n",
    "#     correct_answer=\"Paris.\",\n",
    "#     main_goal=\"Learn how to format the answer exactly in given style\"\n",
    "# )\n",
    "# print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: eholl | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: eholl | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Pythonay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Pythonay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: coda | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: coda | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: learned | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: learned | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: hillo | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: hillo | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: world | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: world | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Pythone | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Pythone | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Coded | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Coded | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Learrn | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Learrn | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Hello | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Hello | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: onpythay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: onpythay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"query\": \"Transform 'hello'\",\n",
    "        \"correct_answer\": \"Ellohay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'world'\",\n",
    "        \"correct_answer\": \"Orldway\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'python'\",\n",
    "        \"correct_answer\": \"Ythonpay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'code'\",\n",
    "        \"correct_answer\": \"Odecay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'learn'\",\n",
    "        \"correct_answer\": \"Earnlay\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    memory = Memory()  # Reset memory for fresh learning\n",
    "    \n",
    "    for _ in range(5):\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            \n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation pattern that converts the input to output\"\n",
    "            )\n",
    "            \n",
    "            print(f\"System Answer: {result['answer']} | Correct Answer: {example['correct_answer']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
