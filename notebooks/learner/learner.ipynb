{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from typing import List, Union\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print\n",
    "\n",
    "from brain.sdk import BrainClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_client = BrainClient(\"http://127.0.0.1:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer to the input query\")\n",
    "\n",
    "class RuleModification(BaseModel):\n",
    "    rule_number: int = Field(..., description=\"The rule number to modify\")\n",
    "    new_content: str = Field(..., description=\"The new content for the rule\")\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    feedback: str = Field(..., description=\"Feedback on the previous answer\")\n",
    "    keep_rules: List[int] = Field(..., description=\"Rule numbers to keep\")\n",
    "    modify_rules: List[RuleModification] = Field(default_factory=list, description=\"Rules to modify\")\n",
    "    new_rules: List[str] = Field(default_factory=list, description=\"New rules to add\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import json\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, content: str, rule_id: int):\n",
    "        self.content = content\n",
    "        self.rule_id = rule_id\n",
    "        self.created_at = datetime.now()\n",
    "        self.last_updated = datetime.now()\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"memory.json\"):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.rules: Dict[int, Rule] = {}\n",
    "        self.next_rule_id = 1\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        data = json.loads(self.file_path.read_text())\n",
    "        self.next_rule_id = data['next_rule_id']\n",
    "        self.rules = {\n",
    "            int(rule_id): Rule(\n",
    "                content=rule['content'],\n",
    "                rule_id=int(rule_id)\n",
    "            )\n",
    "            for rule_id, rule in data['rules'].items()\n",
    "        }\n",
    "\n",
    "    def _save(self):\n",
    "        data = {\n",
    "            'next_rule_id': self.next_rule_id,\n",
    "            'rules': {\n",
    "                str(rule_id): {\n",
    "                    'content': rule.content,\n",
    "                }\n",
    "                for rule_id, rule in self.rules.items()\n",
    "            }\n",
    "        }\n",
    "        self.file_path.write_text(json.dumps(data, indent=2))\n",
    "\n",
    "    def get_rules_context(self) -> str:\n",
    "        # if not self.rules:\n",
    "        #     return \"No existing rules.\"\n",
    "        \n",
    "        return \"Current rules:\\n\" + \"\\n\".join(\n",
    "            f\"{rule.rule_id}. {rule.content}\"\n",
    "            for rule in sorted(self.rules.values(), key=lambda x: x.rule_id)\n",
    "        )\n",
    "\n",
    "    def update_from_feedback(self, feedback: FeedbackResult):\n",
    "        # Convert current rules to set for easier processing\n",
    "        current_rule_ids = set(self.rules.keys())\n",
    "        keep_rules = set(feedback.keep_rules)\n",
    "        \n",
    "        # Remove rules not in keep_rules\n",
    "        rules_to_remove = current_rule_ids - keep_rules\n",
    "        if rules_to_remove:\n",
    "            for rule_id in rules_to_remove:\n",
    "                self.rules.pop(rule_id, None)\n",
    "\n",
    "        # Modify existing rules\n",
    "        if feedback.modify_rules:\n",
    "            for modification in feedback.modify_rules:\n",
    "                if modification.rule_number in self.rules:\n",
    "                    self.rules[modification.rule_number].content = modification.new_content\n",
    "                    self.rules[modification.rule_number].last_updated = datetime.now()\n",
    "\n",
    "        # Add new rules\n",
    "        if feedback.new_rules:\n",
    "            for content in feedback.new_rules:\n",
    "                rule = Rule(content=content, rule_id=self.next_rule_id)\n",
    "                self.rules[self.next_rule_id] = rule\n",
    "                self.next_rule_id += 1\n",
    "\n",
    "        self._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, context: str):\n",
    "    system_prompt = \"\"\"You are an agent designed to provide answers based on learned rules.\n",
    "Apply the rules wisely - not every rule needs to be used for every answer.\n",
    "You are an agent that uses knowledge to generate accurate, generalized answers. \n",
    "Focus on principles and patterns, not specific memorization. Use the context provided to:\n",
    "1. Identify underlying patterns.\n",
    "2. Apply generalized knowledge to new inputs.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Query: {input_query}\n",
    "\n",
    "{context}\n",
    "\n",
    "Using these rules as guidelines, provide your answer:\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(main_goal: str, input_query: str, answer: str, correct_answer: str, context: str):\n",
    "    system_prompt = f\"\"\"You are a learning feedback agent focused on extracting deep insights aligned with a specific goal.\n",
    "\n",
    "MAIN GOAL: {main_goal}\n",
    "\n",
    "Your purpose is to help the system learn HOW to achieve this goal by:\n",
    "1. Analyzing differences between given answers and correct answers\n",
    "2. Extracting detailed knowledge that helps achieve the main goal\n",
    "3. Creating comprehensive rules that guide future responses\n",
    "4. Building a knowledge base focused on the goal's requirements\n",
    "\n",
    "Core Analysis Principles:\n",
    "- Extract general patterns, not specific solutions\n",
    "- Look for underlying principles that achieve the goal\n",
    "- Focus on knowledge that transfers to new situations\n",
    "- Identify what knowledge would help achieve better answers\n",
    "- Consider what deep understanding is missing\n",
    "- Think about what fundamental concepts would improve performance\n",
    "\n",
    "Rules/Knowledge Requirements:\n",
    "- Must directly relate to achieving the main goal\n",
    "- Should be detailed and comprehensive\n",
    "- Must be generally applicable\n",
    "- Should capture underlying principles\n",
    "- Must focus on transferable knowledge\n",
    "- Should build on existing understanding\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"DEEP LEARNING ANALYSIS:\n",
    "\n",
    "GOAL TO ACHIEVE: {main_goal}\n",
    "\n",
    "Current Learning Instance:\n",
    "Input: {input_query}\n",
    "Current Output: {answer}\n",
    "Expected Output: {correct_answer}\n",
    "\n",
    "Existing Knowledge Base:\n",
    "{context}\n",
    "\n",
    "Perform Deep Analysis:\n",
    "1. What fundamental understanding would help achieve the goal here?\n",
    "2. What deeper patterns reveal themselves when comparing outputs?\n",
    "3. What core principles would improve goal achievement?\n",
    "4. What essential knowledge is missing from our current rules?\n",
    "5. What broader understanding would help with similar goals?\n",
    "\n",
    "Provide:\n",
    "1. Rich Analysis: Detailed feedback about what we can learn regarding our goal\n",
    "2. Retained Knowledge: List numbers of rules that contain valid, goal-relevant principles\n",
    "3. Knowledge Updates: List [[rule_number, \"enhanced knowledge or principle\"]]\n",
    "4. New Understanding: Add detailed new rules that capture essential goal-relevant knowledge\n",
    "\n",
    "Focus Areas:\n",
    "- Deep understanding over surface patterns\n",
    "- Core principles over specific solutions\n",
    "- Transferable knowledge over contextual details\n",
    "- Fundamental concepts over specific applications\n",
    "- Goal achievement mechanisms over input-output pairs\n",
    "Your goal is to help the system learn to achieve its main goal by analyzing successes and failures.\n",
    "- Identify positive patterns that led to correct answers.\n",
    "- Identify negative patterns or gaps that caused failures.\n",
    "- Provide insights to refine knowledge for future queries.\n",
    "- Focus on creating rules or principles that generalize well.\n",
    "\n",
    "\n",
    "- If something is working give positive feedback so that the system can learn from it\n",
    "- If something is not working give negative feedback so that the system can learn from it\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(input_query: str, correct_answer: Optional[str] = None, \n",
    "                 main_goal: str = \"Learn to provide accurate and consistent responses\"):\n",
    "    memory = Memory()\n",
    "    context = memory.get_rules_context()\n",
    "    # Get answer using current rules\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Get feedback and evolve rules\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            answer=result.answer,\n",
    "            correct_answer=correct_answer,\n",
    "            context=context\n",
    "        )\n",
    "        # Update memory based on feedback\n",
    "        memory.update_from_feedback(feedback)\n",
    "        \n",
    "        return {\"answer\": result.answer, \"feedback\": feedback}\n",
    "    \n",
    "    return {\"answer\": result.answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = \"What is the capital of France?\"\n",
    "# result1 = process_query(\n",
    "#     input_query=query1,\n",
    "#     correct_answer=\"Paris.\",\n",
    "#     main_goal=\"Learn how to format the answer exactly in given style\"\n",
    "# )\n",
    "# print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: eholl | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: eholl | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Pythonay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Pythonay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: coda | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: coda | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: learned | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: learned | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: hillo | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: hillo | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: world | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: world | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Pythone | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Pythone | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Coded | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Coded | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Learrn | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Learrn | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Hello | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Hello | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: onpythay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: onpythay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"query\": \"Transform 'hello'\",\n",
    "        \"correct_answer\": \"Ellohay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'world'\",\n",
    "        \"correct_answer\": \"Orldway\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'python'\",\n",
    "        \"correct_answer\": \"Ythonpay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'code'\",\n",
    "        \"correct_answer\": \"Odecay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'learn'\",\n",
    "        \"correct_answer\": \"Earnlay\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    memory = Memory()  # Reset memory for fresh learning\n",
    "    \n",
    "    for _ in range(5):\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            \n",
    "            result = process_query(\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation pattern that converts the input to output\"\n",
    "            )\n",
    "            \n",
    "            print(f\"System Answer: {result['answer']} | Correct Answer: {example['correct_answer']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced multi memory CLU\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Input Query] --> B[Operational Reasoner]\n",
    "    B --> C[Generated Answer]\n",
    "    C --> D[Feedback Reasoner]\n",
    "    E[Correct Answer] --> D\n",
    "    F[Main Goal] --> D\n",
    "    \n",
    "    subgraph Memory System\n",
    "        G[Pattern Memory]\n",
    "        H[Success Memory]\n",
    "        I[Failure Memory]\n",
    "        J[Confidence Tracker]\n",
    "    end\n",
    "    \n",
    "    G --> B\n",
    "    H --> B\n",
    "    I --> B\n",
    "    J --> B\n",
    "    \n",
    "    D --> K[Memory Manager]\n",
    "    K --> G\n",
    "    K --> H\n",
    "    K --> I\n",
    "    K --> J\n",
    "\n",
    "    subgraph Feedback Analysis\n",
    "        L[Pattern Extractor]\n",
    "        M[Success Analyzer]\n",
    "        N[Failure Analyzer]\n",
    "        O[Confidence Updater]\n",
    "    end\n",
    "    \n",
    "    D --> L\n",
    "    D --> M\n",
    "    D --> N\n",
    "    D --> O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# Core data structures\n",
    "class ConfidenceLevel(str, Enum):\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "    UNPROVEN = \"unproven\"\n",
    "\n",
    "@dataclass\n",
    "class Insight:\n",
    "    principle: str\n",
    "    reasoning: str\n",
    "    observations: List[str]\n",
    "    counter_observations: List[str]\n",
    "    confidence: ConfidenceLevel\n",
    "    created_at: datetime\n",
    "    last_updated: datetime\n",
    "\n",
    "@dataclass\n",
    "class LearningContext:\n",
    "    successes: List[str]\n",
    "    failures: List[str]\n",
    "    observations: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for reasoner schemas\n",
    "class GeneralizedInsight(BaseModel):\n",
    "    principle: str = Field(..., description=\"The fundamental principle or concept learned from the examples\")\n",
    "    reasoning: str = Field(..., description=\"Explanation of why this principle works or is important\")\n",
    "    supporting_evidence: List[str] = Field(..., description=\"Examples or cases that support this principle\")\n",
    "    refinement_needs: List[str] = Field(..., description=\"Areas where this principle needs improvement or clarification\")\n",
    "\n",
    "class OperationalResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"The transformed output based on learned principles\")\n",
    "    applied_insights: List[str] = Field(..., description=\"List of insights/principles used to generate this answer\")\n",
    "    confidence_assessment: str = Field(..., \n",
    "        description=\"Assessment of confidence in the answer: must be one of 'High confidence: [reason]', 'Medium confidence: [reason]', or 'Low confidence: [reason]'\")\n",
    "\n",
    "class FeedbackResult(BaseModel):\n",
    "    feedback: str = Field(..., description=\"Detailed analysis of what worked and what didn't in the transformation\")\n",
    "    new_insights: List[GeneralizedInsight] = Field(..., description=\"New fundamental principles discovered from this example\")\n",
    "    refined_insights: List[str] = Field(..., description=\"IDs of existing insights that need updating based on this example\")\n",
    "    successful_applications: List[str] = Field(..., description=\"Specific aspects of the transformation that worked well\")\n",
    "    improvement_areas: List[str] = Field(..., description=\"Areas where the transformation could be improved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryConfig:\n",
    "    def __init__(self, \n",
    "                 max_history: int = 10, \n",
    "                 max_observations_per_insight: int = 5,\n",
    "                 max_recent_successes: int = 3,\n",
    "                 max_recent_failures: int = 3):\n",
    "        self.max_history = max_history\n",
    "        self.max_observations_per_insight = max_observations_per_insight\n",
    "        self.max_recent_successes = max_recent_successes\n",
    "        self.max_recent_failures = max_recent_failures\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, file_path: str = \"enhanced_memory.json\", config: Optional[MemoryConfig] = None):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.config = config or MemoryConfig()\n",
    "        self.insights: Dict[str, Insight] = {}\n",
    "        self.learning_context = LearningContext([], [], [])\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not self.file_path.exists():\n",
    "            self._save()\n",
    "            return\n",
    "\n",
    "        data = json.loads(self.file_path.read_text())\n",
    "        \n",
    "        # Load insights\n",
    "        self.insights = {\n",
    "            insight_id: Insight(\n",
    "                principle=i[\"principle\"],\n",
    "                reasoning=i[\"reasoning\"],\n",
    "                observations=i[\"observations\"][-self.config.max_observations_per_insight:],\n",
    "                counter_observations=i[\"counter_observations\"][-self.config.max_observations_per_insight:],\n",
    "                confidence=ConfidenceLevel(i[\"confidence\"]),\n",
    "                created_at=datetime.fromisoformat(i[\"created_at\"]),\n",
    "                last_updated=datetime.fromisoformat(i[\"last_updated\"])\n",
    "            )\n",
    "            for insight_id, i in data.get('insights', {}).items()\n",
    "        }\n",
    "        \n",
    "        # Load learning context with limits\n",
    "        context_data = data.get('learning_context', {})\n",
    "        self.learning_context = LearningContext(\n",
    "            successes=context_data.get('successes', [])[-self.config.max_history:],\n",
    "            failures=context_data.get('failures', [])[-self.config.max_history:],\n",
    "            observations=context_data.get('observations', [])[-self.config.max_history:]\n",
    "        )\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        context_parts = []\n",
    "        \n",
    "        # Add current understanding\n",
    "        context_parts.append(\"=== CURRENT UNDERSTANDING ===\")\n",
    "        for insight_id, insight in self.insights.items():\n",
    "            context_parts.append(f\"\\nPrinciple [{insight.confidence.value}]: {insight.principle}\")\n",
    "            context_parts.append(f\"Why it works: {insight.reasoning}\")\n",
    "            context_parts.append(\"Supporting observations:\")\n",
    "            for obs in insight.observations[-self.config.max_observations_per_insight:]:\n",
    "                context_parts.append(f\"- {obs}\")\n",
    "            if insight.counter_observations:\n",
    "                context_parts.append(\"Areas needing refinement:\")\n",
    "                for obs in insight.counter_observations[-self.config.max_observations_per_insight:]:\n",
    "                    context_parts.append(f\"- {obs}\")\n",
    "\n",
    "        # Add learning context\n",
    "        context_parts.append(\"\\n=== RECENT LEARNINGS ===\")\n",
    "        if self.learning_context.successes:\n",
    "            context_parts.append(\"\\nWhat's working:\")\n",
    "            for success in self.learning_context.successes[-self.config.max_recent_successes:]:\n",
    "                context_parts.append(f\"- {success}\")\n",
    "        \n",
    "        if self.learning_context.failures:\n",
    "            context_parts.append(\"\\nWhat needs improvement:\")\n",
    "            for failure in self.learning_context.failures[-self.config.max_recent_failures:]:\n",
    "                context_parts.append(f\"- {failure}\")\n",
    "\n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "    def update_from_feedback(self, feedback: FeedbackResult):\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Add new insights\n",
    "        for insight in feedback.new_insights:\n",
    "            insight_id = f\"insight_{len(self.insights) + 1}\"\n",
    "            self.insights[insight_id] = Insight(\n",
    "                principle=insight.principle,\n",
    "                reasoning=insight.reasoning,\n",
    "                observations=insight.supporting_evidence[-self.config.max_observations_per_insight:],\n",
    "                counter_observations=insight.refinement_needs[-self.config.max_observations_per_insight:],\n",
    "                confidence=ConfidenceLevel.UNPROVEN,\n",
    "                created_at=current_time,\n",
    "                last_updated=current_time\n",
    "            )\n",
    "\n",
    "        # Update learning context with limits\n",
    "        self.learning_context.successes.extend(feedback.successful_applications)\n",
    "        self.learning_context.failures.extend(feedback.improvement_areas)\n",
    "        \n",
    "        # Apply limits\n",
    "        self.learning_context.successes = self.learning_context.successes[-self.config.max_history:]\n",
    "        self.learning_context.failures = self.learning_context.failures[-self.config.max_history:]\n",
    "\n",
    "        # Update existing insights\n",
    "        for insight_id in feedback.refined_insights:\n",
    "            if insight_id in self.insights:\n",
    "                insight = self.insights[insight_id]\n",
    "                insight.last_updated = current_time\n",
    "                \n",
    "                # Update confidence based on success rate\n",
    "                success_rate = len(insight.observations) / (\n",
    "                    len(insight.observations) + len(insight.counter_observations)\n",
    "                )\n",
    "                if success_rate > 0.8:\n",
    "                    insight.confidence = ConfidenceLevel.HIGH\n",
    "                elif success_rate > 0.6:\n",
    "                    insight.confidence = ConfidenceLevel.MEDIUM\n",
    "                else:\n",
    "                    insight.confidence = ConfidenceLevel.LOW\n",
    "\n",
    "        self._save()\n",
    "    \n",
    "    def _save(self):\n",
    "        \"\"\"Save the current state to the JSON file.\"\"\"\n",
    "        data = {\n",
    "            'insights': {\n",
    "                insight_id: {\n",
    "                    'principle': insight.principle,\n",
    "                    'reasoning': insight.reasoning,\n",
    "                    'observations': insight.observations,\n",
    "                    'counter_observations': insight.counter_observations,\n",
    "                    'confidence': insight.confidence.value,\n",
    "                    'created_at': insight.created_at.isoformat(),\n",
    "                    'last_updated': insight.last_updated.isoformat()\n",
    "                }\n",
    "                for insight_id, insight in self.insights.items()\n",
    "            },\n",
    "            'learning_context': {\n",
    "                'successes': self.learning_context.successes,\n",
    "                'failures': self.learning_context.failures,\n",
    "                'observations': self.learning_context.observations\n",
    "            }\n",
    "        }\n",
    "        self.file_path.write_text(json.dumps(data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@brain_client.reasoner(schema=OperationalResult)\n",
    "def operational_reasoner(input_query: str, context: str):\n",
    "    system_prompt = \"\"\"You are a learning system that applies generalized principles to solve problems.\n",
    "Focus on using fundamental insights rather than memorized patterns.\n",
    "\n",
    "When generating an answer:\n",
    "1. Review the principles we've learned about transformations\n",
    "2. Consider what general insights apply to this case\n",
    "3. Apply the most relevant fundamental concepts\n",
    "4. Explain your reasoning based on core principles\n",
    "\n",
    "Remember:\n",
    "- Use general principles rather than specific examples\n",
    "- Apply fundamental concepts we've learned\n",
    "- Consider how insights about structure and patterns apply\n",
    "- Think about why certain approaches should work here\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Query: {input_query}\n",
    "\n",
    "Our Current Understanding:\n",
    "{context}\n",
    "\n",
    "Please analyze the query using our learned principles and insights.\n",
    "Generate an answer based on fundamental concepts rather than specific patterns.\n",
    "Explain which insights you applied and why.\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "@brain_client.reasoner(schema=FeedbackResult)\n",
    "def feedback_reasoner(main_goal: str, input_query: str, answer: str, correct_answer: str, context: str):\n",
    "    system_prompt = f\"\"\"You are a learning system focused on discovering fundamental principles.\n",
    "\n",
    "MAIN GOAL: {main_goal}\n",
    "\n",
    "Your key responsibilities:\n",
    "1. Extract general principles that explain why transformations work\n",
    "2. Identify fundamental concepts that apply across cases\n",
    "3. Build deep understanding of transformation patterns\n",
    "4. Learn generalizable insights from specific examples\n",
    "\n",
    "Analysis Approach:\n",
    "- Focus on WHY transformations work or fail\n",
    "- Look for underlying principles that apply broadly\n",
    "- Consider what fundamental concepts are at play\n",
    "- Think about structural patterns in transformations\n",
    "\n",
    "Key Questions:\n",
    "- What general principle explains this transformation?\n",
    "- Why does this approach work (or not work)?\n",
    "- What fundamental concept can we learn from this?\n",
    "- How would this insight apply to new cases?\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"LEARNING ANALYSIS:\n",
    "\n",
    "Input: {input_query}\n",
    "Generated Answer: {answer}\n",
    "Correct Answer: {correct_answer}\n",
    "\n",
    "Current Understanding:\n",
    "{context}\n",
    "\n",
    "Please analyze and provide:\n",
    "1. What fundamental principles explain this transformation?\n",
    "2. Why do these principles work or fail?\n",
    "3. What general insights can we extract?\n",
    "4. How can these insights help with future transformations?\n",
    "\n",
    "Focus on building deeper understanding rather than collecting examples.\"\"\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "# register reasoners\n",
    "operational_reasoner_id = operational_reasoner.register()\n",
    "feedback_reasoner_id = feedback_reasoner.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(\n",
    "    input_query: str,\n",
    "    memory: Memory,\n",
    "    correct_answer: Optional[str] = None,\n",
    "    main_goal: str = \"Learn transformation patterns that consistently produce correct outputs\"\n",
    "):\n",
    "    context = memory.get_context()\n",
    "    \n",
    "    # Get answer using current insights\n",
    "    result = brain_client.use(operational_reasoner_id)(\n",
    "        input_query=input_query,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    if correct_answer is not None:\n",
    "        # Get feedback and evolve insights\n",
    "        feedback = brain_client.use(feedback_reasoner_id)(\n",
    "            main_goal=main_goal,\n",
    "            input_query=input_query,\n",
    "            answer=result.answer,\n",
    "            correct_answer=correct_answer,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Update memory based on feedback\n",
    "        memory.update_from_feedback(feedback)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": result.answer,\n",
    "            \"applied_insights\": result.applied_insights,  # Changed from applied_patterns\n",
    "            \"confidence\": result.confidence_assessment,\n",
    "            \"feedback\": feedback\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"answer\": result.answer,\n",
    "        \"applied_insights\": result.applied_insights,  # Changed from applied_patterns\n",
    "        \"confidence\": result.confidence_assessment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: olleh | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: olleh | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: dlrow | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: dlrow | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: onpyth | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: onpyth | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orlwdway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orlwdway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: onpythay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: onpythay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ellohay | Correct Answer: Ellohay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ellohay | Correct Answer: Ellohay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Orldway | Correct Answer: Orldway\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Orldway | Correct Answer: Orldway\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Ythonpay | Correct Answer: Ythonpay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Ythonpay | Correct Answer: Ythonpay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: Odecay | Correct Answer: Odecay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: Odecay | Correct Answer: Odecay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System Answer: earnlay | Correct Answer: Earnlay\n",
       "</pre>\n"
      ],
      "text/plain": [
       "System Answer: earnlay | Correct Answer: Earnlay\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples = [\n",
    "    {\n",
    "        \"query\": \"Transform 'hello'\",\n",
    "        \"correct_answer\": \"Ellohay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'world'\",\n",
    "        \"correct_answer\": \"Orldway\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'python'\",\n",
    "        \"correct_answer\": \"Ythonpay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'code'\",\n",
    "        \"correct_answer\": \"Odecay\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Transform 'learn'\",\n",
    "        \"correct_answer\": \"Earnlay\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def train_pattern_learner():\n",
    "    config = MemoryConfig(\n",
    "        max_history=10,\n",
    "        max_observations_per_insight=5,\n",
    "        max_recent_successes=3,\n",
    "        max_recent_failures=3\n",
    "    )\n",
    "    memory = Memory(file_path=\"Trial_1.json\", config=config)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        for i, example in enumerate(training_examples, 1):\n",
    "            \n",
    "            result = process_query(\n",
    "                memory=memory,\n",
    "                input_query=example['query'],\n",
    "                correct_answer=example['correct_answer'],\n",
    "                main_goal=\"Learn the hidden transformation pattern that converts the input to output\"\n",
    "            )\n",
    "            \n",
    "            print(f\"System Answer: {result['answer']} | Correct Answer: {example['correct_answer']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "train_pattern_learner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
